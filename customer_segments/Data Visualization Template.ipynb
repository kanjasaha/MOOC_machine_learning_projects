{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "### Kanja Saha\n",
    "\n",
    "## Steps\n",
    "1. <a href='#import_lib'>Import Libraries</a>\n",
    "1. <a href='#import_data'>Import Data</a>\n",
    "2. <a href='#preprocess'>Preprocess Data</a>\n",
    "3. <a href='#explore'>Explore Data</a>\n",
    "3. <a href='#implement'>Implement Algorithms</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "<a id='import_lib'></a>\n",
    "In general, import all libraries before importing data. However, for learning purpose, import libraries in each step as needed. This is will give a better understanding of the libraries and their functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "<a id='import_data'></a>\n",
    "In general, import all needed libraries before importing data. If this is a learning execise, import libraries in each step as needed. This is will give a better understanding of the libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 541909 rows(samples) with 8 columns(features) each.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recency</th>\n",
       "      <th>duration</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_count</th>\n",
       "      <th>return_amount</th>\n",
       "      <th>return_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12346.0</th>\n",
       "      <td>325</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12347.0</th>\n",
       "      <td>1</td>\n",
       "      <td>366</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12348.0</th>\n",
       "      <td>74</td>\n",
       "      <td>283</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12349.0</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12350.0</th>\n",
       "      <td>309</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Recency  duration  purchase_amount  purchase_count  return_amount  \\\n",
       "CustomerID                                                                      \n",
       "12346.0         325         1                1               1              1   \n",
       "12347.0           1       366              182               0              0   \n",
       "12348.0          74       283               31               0              0   \n",
       "12349.0          18         1               73               0              0   \n",
       "12350.0         309         1               17               0              0   \n",
       "\n",
       "            return_count  \n",
       "CustomerID                \n",
       "12346.0                1  \n",
       "12347.0                0  \n",
       "12348.0                0  \n",
       "12349.0                0  \n",
       "12350.0                0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Load the dataset into pandas dataframe\n",
    "raw_data_all = pd.read_excel(\"Online_Retail.csv\")\n",
    "print (\"Dataset has {} rows(samples) with {} columns(features) each.\".format(*raw_data_all.shape))\n",
    "\n",
    "# since we are looking for customer info, drop all records that has no customerid\n",
    "raw_data_all=raw_data_all.dropna(subset=['CustomerID'])\n",
    "raw_data=raw_data_all\n",
    "# display the top 5 rows of the dataset\n",
    "raw_data_all.head(5)\n",
    "\n",
    "#summary of dataset's distribution\n",
    "#raw_data_all.groupby('Description').size()\n",
    "#raw_data_all[raw_data_all.Description=='thrown away']\n",
    "#raw_data_all[raw_data_all.StockCode=='84611B']\n",
    "raw_data_all.describe()\n",
    "\n",
    "#items with negative quantity implies returned items, and 0 implies no purchase\n",
    "#raw_data[raw_data.Quantity<=0].head(5)\n",
    "\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "LastTransactionDate=raw_data['InvoiceDate'].max()\n",
    "\n",
    "data=raw_data.groupby('CustomerID').apply(lambda x: pd.Series(dict(\n",
    "    duration=(pd.to_datetime(x.InvoiceDate.max()) - pd.to_datetime(x.InvoiceDate.min())).days+1,\n",
    "    Recency=(LastTransactionDate-x.InvoiceDate.max()).days,\n",
    "    return_count=(x.Quantity < 0).sum(),\n",
    "    purchase_count=(x.Quantity < 0).sum(),\n",
    "    return_amount=(x.Quantity*x.UnitPrice < 0).sum(),\n",
    "    purchase_amount=(x.UnitPrice*x.Quantity > 0).sum())))\n",
    "data.head()\n",
    "\n",
    "#pd.to_datetime(raw_data.InvoiceDate)).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantity</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>406829.000000</td>\n",
       "      <td>406829.000000</td>\n",
       "      <td>406829.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.061303</td>\n",
       "      <td>3.460471</td>\n",
       "      <td>15287.690570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>248.693370</td>\n",
       "      <td>69.315162</td>\n",
       "      <td>1713.600303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-80995.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12346.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>13953.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>15152.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>16791.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80995.000000</td>\n",
       "      <td>38970.000000</td>\n",
       "      <td>18287.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Quantity      UnitPrice     CustomerID\n",
       "count  406829.000000  406829.000000  406829.000000\n",
       "mean       12.061303       3.460471   15287.690570\n",
       "std       248.693370      69.315162    1713.600303\n",
       "min    -80995.000000       0.000000   12346.000000\n",
       "25%         2.000000       1.250000   13953.000000\n",
       "50%         5.000000       1.950000   15152.000000\n",
       "75%        12.000000       3.750000   16791.000000\n",
       "max     80995.000000   38970.000000   18287.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary of dataset's distribution\n",
    "import numpy as np\n",
    "raw_data['CustomerID'] = raw_data['CustomerID'].astype(np.int64)\n",
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>C536379</td>\n",
       "      <td>D</td>\n",
       "      <td>Discount</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010-12-01 09:41:00</td>\n",
       "      <td>27.50</td>\n",
       "      <td>14527</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>C536383</td>\n",
       "      <td>35004C</td>\n",
       "      <td>SET OF 3 COLOURED  FLYING DUCKS</td>\n",
       "      <td>-1</td>\n",
       "      <td>2010-12-01 09:49:00</td>\n",
       "      <td>4.65</td>\n",
       "      <td>15311</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>C536391</td>\n",
       "      <td>22556</td>\n",
       "      <td>PLASTERS IN TIN CIRCUS PARADE</td>\n",
       "      <td>-12</td>\n",
       "      <td>2010-12-01 10:24:00</td>\n",
       "      <td>1.65</td>\n",
       "      <td>17548</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>C536391</td>\n",
       "      <td>21984</td>\n",
       "      <td>PACK OF 12 PINK PAISLEY TISSUES</td>\n",
       "      <td>-24</td>\n",
       "      <td>2010-12-01 10:24:00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>17548</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>C536391</td>\n",
       "      <td>21983</td>\n",
       "      <td>PACK OF 12 BLUE PAISLEY TISSUES</td>\n",
       "      <td>-24</td>\n",
       "      <td>2010-12-01 10:24:00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>17548</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    InvoiceNo StockCode                       Description  Quantity  \\\n",
       "141   C536379         D                          Discount        -1   \n",
       "154   C536383    35004C   SET OF 3 COLOURED  FLYING DUCKS        -1   \n",
       "235   C536391     22556    PLASTERS IN TIN CIRCUS PARADE        -12   \n",
       "236   C536391     21984  PACK OF 12 PINK PAISLEY TISSUES        -24   \n",
       "237   C536391     21983  PACK OF 12 BLUE PAISLEY TISSUES        -24   \n",
       "\n",
       "            InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "141 2010-12-01 09:41:00      27.50       14527  United Kingdom  \n",
       "154 2010-12-01 09:49:00       4.65       15311  United Kingdom  \n",
       "235 2010-12-01 10:24:00       1.65       17548  United Kingdom  \n",
       "236 2010-12-01 10:24:00       0.29       17548  United Kingdom  \n",
       "237 2010-12-01 10:24:00       0.29       17548  United Kingdom  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#items with negative quantity implies returned items, and 0 implies no purchase\n",
    "raw_data[raw_data.Quantity<=0].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'preprocess_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d874c6c19cc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocess_data\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutliers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove_outliers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'preprocess_data'"
     ]
    }
   ],
   "source": [
    "import preprocess_data as o\n",
    "data,outliers,message=o.remove_outliers(data,False)\n",
    "print (message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Produce a scatter matrix for each pair of features in the data\n",
    "pd.scatter_matrix(data, alpha = 0.3, figsize = (14,8), diagonal = 'kde');\n",
    "\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess_data as o\n",
    "data,outliers,message=o.remove_outliers(data,True)\n",
    "print (message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.scatter_matrix(data, alpha = 0.3, figsize = (14,8), diagonal = 'kde');\n",
    "\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NORMALIZE DATA \n",
    "import preprocess_data as o\n",
    "n_data=o.normalize_data(data)\n",
    "#print (message)\n",
    "n_data.head(5)\n",
    "n_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.scatter_matrix(data, alpha = 0.3, figsize = (14,8), diagonal = 'kde');\n",
    "\n",
    "n_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n_data.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a description of the dataset\n",
    "display(data.describe())\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "products=list(data.columns.values)\n",
    "for  x in products:\n",
    "    plt.figure(x)\n",
    "    sns.distplot(data[x]);\n",
    "sns.pairplot(data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make a copy of the DataFrame, using the 'drop' function to drop the given feature\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "    \n",
    "for  x in products:\n",
    "    \n",
    "    new_data = data.drop([x], axis = 1, inplace = False)\n",
    "    target = data[x]\n",
    "\n",
    "    # TODO: Split the data into training and testing sets(0.25) using the given feature as the target\n",
    "    # Set a random state.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(new_data, target, test_size=0.25, random_state=12)\n",
    "\n",
    "    # TODO: Create a decision tree regressor and fit it to the training set\n",
    "    regressor = DecisionTreeRegressor()\n",
    "    regressor.fit(X_train, y_train);\n",
    "\n",
    "    # TODO: Report the score of the prediction using the testing set\n",
    "    score = regressor.score(X_test,y_test)\n",
    "    print('Score for ''\\033[1m'' {} ''\\033[0m'' as target feature: ''\\033[1m'' {} ''\\033[0m'''.format(x,score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation: Outlier Detection\n",
    "Detecting outliers in the data is extremely important in the data preprocessing step of any analysis. The presence of outliers can often skew results which take into consideration these data points. There are many \"rules of thumb\" for what constitutes an outlier in a dataset. Here, we will use [Tukey's Method for identfying outliers](http://datapigtechnologies.com/blog/index.php/highlighting-outliers-in-your-data-with-the-tukey-method/): An *outlier step* is calculated as 1.5 times the interquartile range (IQR). A data point with a feature that is beyond an outlier step outside of the IQR for that feature is considered abnormal.\n",
    "\n",
    "In the code block below, you will need to implement the following:\n",
    " - Assign the value of the 25th percentile for the given feature to `Q1`. Use `np.percentile` for this.\n",
    " - Assign the value of the 75th percentile for the given feature to `Q3`. Again, use `np.percentile`.\n",
    " - Assign the calculation of an outlier step for the given feature to `step`.\n",
    " - Optionally remove data points from the dataset by adding indices to the `outliers` list.\n",
    "\n",
    "**NOTE:** If you choose to remove any outliers, ensure that the sample data does not contain any of these points!  \n",
    "Once you have performed this implementation, the dataset will be stored in the variable `good_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply PCA by fitting the good data with the same number of dimensions as features\n",
    "good_data=data\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(copy=True, iterated_power='auto', n_components=6, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False)\n",
    "pca.fit(good_data)\n",
    "\n",
    "# TODO: Transform log_samples using the PCA fit above\n",
    "\n",
    "#pca_samples = pca.transform(log_samples)\n",
    "\n",
    "# Generate PCA results plot\n",
    "pca_results = vs.pca_results(good_data, pca)\n",
    "\n",
    "print (pca_results['Explained Variance'].cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 2, figsize=(7, 7), sharex=True)\n",
    "sns.distplot( x , color=\"skyblue\", ax=axes[0, 0])\n",
    "sns.distplot( y , color=\"olive\", ax=axes[0, 1])\n",
    "sns.distplot(z , color=\"gold\", ax=axes[1, 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "fig = plt.figure(figsize = (6,4))\n",
    "title = fig.suptitle(\"Purchase Recency\", fontsize=14)\n",
    "fig.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "ax = fig.add_subplot(1,1, 1)\n",
    "ax.set_xlabel(\"rRecency\")\n",
    "ax.set_ylabel(\"Count\") \n",
    "ax.text(1.2, 800, r'$\\mu$='+str(round(data['recency'].mean(),2)), \n",
    "         fontsize=12)\n",
    "freq, bins, patches = ax.hist(data['recency'], color='green', bins=15,\n",
    "                                    edgecolor='black', linewidth=1)\n",
    "                                    \n",
    "\n",
    "# Density Plot\n",
    "fig = plt.figure(figsize = (6, 4))\n",
    "title = fig.suptitle(\"Purchase Recency\", fontsize=14)\n",
    "fig.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "ax1 = fig.add_subplot(1,1, 1)\n",
    "ax1.set_xlabel(\"Recency\")\n",
    "ax1.set_ylabel(\"Count\") \n",
    "sns.kdeplot(data['recency'], ax=ax1, shade=True, color='steelblue')\n",
    "                                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "fig = plt.figure(figsize = (6,4))\n",
    "title = fig.suptitle(\"Purchase Frequency\", fontsize=14)\n",
    "fig.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "ax = fig.add_subplot(1,1, 1)\n",
    "ax.set_xlabel(\"Frequency\")\n",
    "ax.set_ylabel(\"Count\") \n",
    "ax.text(1.2, 800, r'$\\mu$='+str(round(data['frequency'].mean(),2)), \n",
    "         fontsize=12)\n",
    "freq, bins, patches = ax.hist(data['frequency'], color='green', bins=15,\n",
    "                                    edgecolor='black', linewidth=1)\n",
    "                                    \n",
    "\n",
    "# Density Plot\n",
    "fig = plt.figure(figsize = (6, 4))\n",
    "title = fig.suptitle(\"Purchase Frequency\", fontsize=14)\n",
    "fig.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "ax1 = fig.add_subplot(1,1, 1)\n",
    "ax1.set_xlabel(\"Frequency\")\n",
    "ax1.set_ylabel(\"Count\") \n",
    "sns.kdeplot(data['frequency'], ax=ax1, shade=True, color='steelblue')\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "fig = plt.figure(figsize = (6,4))\n",
    "title = fig.suptitle(\"Monetization\", fontsize=14)\n",
    "fig.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "ax = fig.add_subplot(1,1, 1)\n",
    "ax.set_xlabel(\"monetization\")\n",
    "ax.set_ylabel(\"Count\") \n",
    "ax.text(1.2, 800, r'$\\mu$='+str(round(data['monetization'].mean(),2)), \n",
    "         fontsize=12)\n",
    "freq, bins, patches = ax.hist(data['monetization'], color='green', bins=15,\n",
    "                                    edgecolor='black', linewidth=1)\n",
    "                                    \n",
    "\n",
    "# Density Plot\n",
    "fig = plt.figure(figsize = (6, 4))\n",
    "title = fig.suptitle(\"Monetization\", fontsize=14)\n",
    "fig.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "ax1 = fig.add_subplot(1,1, 1)\n",
    "ax1.set_xlabel(\"Monetization\")\n",
    "ax1.set_ylabel(\"Count\") \n",
    "sns.kdeplot(data['monetization'], ax=ax1, shade=True, color='steelblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Plot\n",
    "fig = plt.figure(figsize = (6, 4))\n",
    "title = fig.suptitle(\"Recency Count\", fontsize=14)\n",
    "fig.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "ax = fig.add_subplot(1,1, 1)\n",
    "ax.set_xlabel(\"Frequency\")\n",
    "ax.set_ylabel(\"Count\") \n",
    "w_q = data['frequency'].value_counts()\n",
    "w_q = (list(w_q.index), list(w_q.values))\n",
    "ax.tick_params(axis='both', which='major', labelsize=8.5)\n",
    "bar = ax.bar(w_q[0], w_q[1], color='steelblue', \n",
    "        edgecolor='black', linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix Heatmap\n",
    "f, ax = plt.subplots(figsize=(10, 6))\n",
    "corr = data.corr()\n",
    "hm = sns.heatmap(round(corr,2), annot=True, ax=ax, cmap=\"coolwarm\",fmt='.2f',\n",
    "                 linewidths=.05)\n",
    "f.subplots_adjust(top=0.93)\n",
    "t= f.suptitle('Correlation Heatmap', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair-wise Scatter Plots\n",
    "cols = ['recency', 'frequency', 'monetization']\n",
    "pp = sns.pairplot(data[cols], size=1.8, aspect=1.8,\n",
    "                  plot_kws=dict(edgecolor=\"k\", linewidth=0.5),\n",
    "                  diag_kind=\"kde\", diag_kws=dict(shade=True))\n",
    "\n",
    "fig = pp.fig \n",
    "fig.subplots_adjust(top=0.93, wspace=0.3)\n",
    "t = fig.suptitle('Pairwise Plots', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimalK(data, nrefs=3, maxClusters=15):\n",
    "    \"\"\"\n",
    "    Calculates KMeans optimal K using Gap Statistic from Tibshirani, Walther, Hastie\n",
    "    Params:\n",
    "        data: ndarry of shape (n_samples, n_features)\n",
    "        nrefs: number of sample reference datasets to create\n",
    "        maxClusters: Maximum number of clusters to test for\n",
    "    Returns: (gaps, optimalK)\n",
    "    \"\"\"\n",
    "    gaps = np.zeros((len(range(1, maxClusters)),))\n",
    "    resultsdf = pd.DataFrame({'clusterCount':[], 'gap':[]})\n",
    "    for gap_index, k in enumerate(range(1, maxClusters)):\n",
    "\n",
    "        # Holder for reference dispersion results\n",
    "        refDisps = np.zeros(nrefs)\n",
    "\n",
    "        # For n references, generate random sample and perform kmeans getting resulting dispersion of each loop\n",
    "        for i in range(nrefs):\n",
    "            \n",
    "            # Create new random reference set\n",
    "            randomReference = np.random.random_sample(size=data.shape)\n",
    "            \n",
    "            # Fit to it\n",
    "            km = KMeans(k)\n",
    "            km.fit(randomReference)\n",
    "            \n",
    "            refDisp = km.inertia_\n",
    "            refDisps[i] = refDisp\n",
    "\n",
    "        # Fit cluster to original data and create dispersion\n",
    "        km = KMeans(k)\n",
    "        km.fit(data)\n",
    "        \n",
    "        origDisp = km.inertia_\n",
    "\n",
    "        # Calculate gap statistic\n",
    "        gap = np.log(np.mean(refDisps)) - np.log(origDisp)\n",
    "\n",
    "        # Assign this loop's gap statistic to gaps\n",
    "        gaps[gap_index] = gap\n",
    "        \n",
    "        resultsdf = resultsdf.append({'clusterCount':k, 'gap':gap}, ignore_index=True)\n",
    "\n",
    "    return (gaps.argmax() + 1, resultsdf)  # Plus 1 because index of 0 means 1 cluster is optimal, index 2 = 3 clusters are optimal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k, gapdf = optimalK(data, nrefs=5, maxClusters=25)\n",
    "print ('Optimal k is: ', k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gapdf.clusterCount, gapdf.gap, linewidth=3)\n",
    "plt.scatter(gapdf[gapdf.clusterCount == k].clusterCount, gapdf[gapdf.clusterCount == k].gap, s=250, c='r')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Cluster Count')\n",
    "plt.ylabel('Gap Value')\n",
    "plt.title('Gap Values by Cluster Count')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
